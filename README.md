ğŸš€ RAG â€“ Financial Reports QA (LangChain + HuggingFace + FAISS)

Sistema de inteligÃªncia artificial para consulta factual de relatÃ³rios anuais corporativos usando Retrieval-Augmented Generation (RAG).

> ğŸ’¡ **Novo no projeto?** Veja a seÃ§Ã£o [InstalaÃ§Ã£o RÃ¡pida](#-instalaÃ§Ã£o-rÃ¡pida-primeira-vez) abaixo para comeÃ§ar em minutos!

## ğŸ¯ Objetivo de NegÃ³cio

**Problema:** Consultas manuais em relatÃ³rios extensos (100+ pÃ¡ginas) sÃ£o lentas e sujeitas a erros.

**SoluÃ§Ã£o:** Pipeline RAG que indexa PDFs, recupera os trechos mais relevantes e gera respostas objetivas e auditÃ¡veis com base no contexto recuperado.

## ğŸ“Š Destaques

- **Revenue 2024** â†’ $64.9 billion
- **R&D spend 2024** â†’ $1.15 billion
- **Markets** â†’ North America, EMEA (Europe, Middle East and Africa) and Growth Markets
- **Risk taxonomy** â†’ Business, Financial, Operational, Legal & Regulatory

## ğŸ§  Arquitetura TÃ©cnica

### Pipeline de Dados
```
PDFs â†’ IngestÃ£o â†’ Chunking â†’ Embeddings â†’ FAISS â†’ Retriever â†’ LLM (Few-Shot) â†’ Resposta
```

### Componentes

1. **IngestÃ£o** (`ingestao_pdf.py`): ExtraÃ§Ã£o de texto de PDFs usando PyPDF via LangChain Community
2. **Chunking** (`chunking.py`): DivisÃ£o de texto em chunks com RecursiveCharacterTextSplitter (1000 caracteres, overlap 200)
3. **Embeddings** (`embedding.py`): GeraÃ§Ã£o de embeddings com HuggingFace all-MiniLM-L6-v2 e armazenamento em FAISS
4. **Busca Manual** (`busca_manual.py`): Consultas diretas ao Ã­ndice vetorial para testes
5. **QA Chain** (`qa_chain.py`): Pipeline completo de retrieval e generation com MMR e Few-Shot prompting
6. **Interface Streamlit** (`app_user.py`): AplicaÃ§Ã£o web interativa com scoring customizado, highlighting e post-processing

## ğŸ› ï¸ Stack TecnolÃ³gica

- **Python** 3.13+
- **LangChain** 0.2+ (LCEL, retrievers, vectorstores)
- **Embeddings:** HuggingFace sentence-transformers (all-MiniLM-L6-v2)
- **Vector Store:** FAISS (CPU)
- **LLM:** Google Flan-T5-base (offline, via transformers)
- **UI:** Streamlit 1.38+

## ğŸ—ï¸ Estrutura do Projeto

```
rag/
â”œâ”€â”€ Data/                      # PDFs de entrada
â”œâ”€â”€ ingestao_pdf.py            # ExtraÃ§Ã£o de texto
â”œâ”€â”€ chunking.py                # DivisÃ£o em chunks
â”œâ”€â”€ embedding.py               # GeraÃ§Ã£o de embeddings e Ã­ndice FAISS
â”œâ”€â”€ busca_manual.py            # Consultas manuais ao Ã­ndice
â”œâ”€â”€ qa_chain.py               # Pipeline RAG completo (linha de comando)
â”œâ”€â”€ app_user.py               # Interface Streamlit (aplicaÃ§Ã£o principal)
â”œâ”€â”€ app.py                    # Interface Streamlit alternativa
â”œâ”€â”€ requirements.txt          # DependÃªncias do projeto
â”œâ”€â”€ vectorstore_index/        # Ãndice FAISS persistido
â”œâ”€â”€ docs/reports/             # RelatÃ³rios Markdown gerados automaticamente
â””â”€â”€ logs/                     # Logs de execuÃ§Ã£o
```

## âš™ï¸ ConfiguraÃ§Ãµes TÃ©cnicas

### Chunking
- `chunk_size=1000` caracteres
- `chunk_overlap=200` caracteres

### Retrieval
- **MMR** (qa_chain.py): `k=3`, `fetch_k=25`, `lambda_mult=0.5`
- **Similarity Search** (app_user.py): Scoring customizado baseado em keywords, nÃºmeros e sinÃ´nimos

### Context Window
- Streamlit: `max_chars=2200`
- Linha de comando: `max_chars=1800`

### Few-Shot Prompting
- Streamlit: 15 exemplos cobrindo mÃºltiplos cenÃ¡rios (revenue, income, R&D, risks, markets, employees, ESG)
- Linha de comando: 3 exemplos bÃ¡sicos

## ğŸš€ Como Executar

### ğŸ“¥ InstalaÃ§Ã£o RÃ¡pida (Primeira Vez)

**1. Clonar o repositÃ³rio:**
```bash
git clone https://github.com/Fergab1/rag-complete.git
cd rag-complete
```

**2. Criar e ativar ambiente virtual:**
```bash
# Windows (PowerShell)
python -m venv venv
.\venv\Scripts\Activate

# Linux/Mac
python3 -m venv venv
source venv/bin/activate
```

**3. Instalar dependÃªncias:**
```bash
pip install -r requirements.txt
```
âš ï¸ **IMPORTANTE:** Certifique-se de que o ambiente virtual estÃ¡ ativado antes de instalar. Se der erro de mÃ³dulo nÃ£o encontrado, verifique se o `(venv)` aparece no inÃ­cio do prompt do terminal.

**4. Adicionar PDF na pasta Data (OBRIGATÃ“RIO):**
- âš ï¸ **CRÃTICO:** O PDF deve estar na pasta `Data/` ANTES de executar o prÃ³ximo passo!
- A pasta `Data/` estÃ¡ vazia por padrÃ£o (nÃ£o commitamos PDFs grandes)
- **OpÃ§Ã£o A - Usar o PDF da Accenture (recomendado para teste):**
  - Baixe o "Accenture Fiscal 2024 Annual Report" em: https://www.accenture.com/us-en/about/company/annual-report
  - Renomeie para `accenture-fiscal-2024-annual-report.pdf` (nome exato!)
  - Coloque na pasta `Data/` (crie a pasta se nÃ£o existir)
  - Verifique se o arquivo estÃ¡ lÃ¡: `Data/accenture-fiscal-2024-annual-report.pdf`
- **OpÃ§Ã£o B - Usar seu prÃ³prio PDF:**
  - Coloque seu PDF na pasta `Data/`
  - Atualize o caminho em `embedding.py` (linha 12) se necessÃ¡rio
- ğŸ“ **Estrutura esperada:** `rag-complete/Data/accenture-fiscal-2024-annual-report.pdf`

**5. Criar o Ã­ndice FAISS:**
```bash
python embedding.py
```
â±ï¸ Isso pode levar alguns minutos na primeira vez (baixa o modelo de embeddings)

**6. Executar a aplicaÃ§Ã£o:**
```bash
streamlit run app_user.py
```

O navegador abrirÃ¡ automaticamente em `http://localhost:8501`

---

### ğŸ“‹ Passo a Passo Detalhado

#### 1. ConfiguraÃ§Ã£o do Ambiente

```bash
# Criar ambiente virtual
python -m venv venv

# Ativar ambiente virtual
# Windows (PowerShell)
.\venv\Scripts\Activate
# Linux/Mac
source venv/bin/activate

# Instalar dependÃªncias
pip install -r requirements.txt
```

#### 2. PreparaÃ§Ã£o dos Dados

```bash
# Adicionar PDF(s) na pasta Data/
# Exemplo: Data/accenture-fiscal-2024-annual-report.pdf
```

#### 3. CriaÃ§Ã£o do Ãndice

```bash
# Gerar embeddings e criar Ã­ndice FAISS
python embedding.py
```

#### 4. ExecuÃ§Ã£o

**OpÃ§Ã£o A: Interface Streamlit (Recomendado)**
```bash
streamlit run app_user.py
```

**OpÃ§Ã£o B: Linha de Comando**
```bash
# Busca manual (testes)
python busca_manual.py

# Pipeline completo (gera relatÃ³rios em docs/reports/)
python qa_chain.py
```

## âœ¨ Features do Streamlit

- **Scoring Customizado:** Sistema de pontuaÃ§Ã£o para melhorar a relevÃ¢ncia dos chunks recuperados
- **Highlighting Visual:** Destaque automÃ¡tico de nÃºmeros, termos financeiros e palavras-chave nas sources
- **Post-processing:** Tratamento inteligente de respostas para melhorar formataÃ§Ã£o e precisÃ£o
- **Filtragem de Sources:** SeleÃ§Ã£o automÃ¡tica das fontes mais relevantes para cada resposta
- **Interface Interativa:** Consultas em tempo real com feedback visual

## ğŸ“„ RelatÃ³rios e EvidÃªncias

ApÃ³s executar `qa_chain.py`, sÃ£o gerados automaticamente:
- Arquivos Markdown em `docs/reports/<timestamp>/` com fontes, contexto e resposta para cada query
- Ãndice consolidado em `index.md`
- Logs completos em `logs/qa_latest.txt`

## ğŸ” Exemplos de Queries

- What was Accenture's total revenue in 2024?
- How much did the company spend on research and development in 2024?
- In which markets does Accenture operate?
- What are the main risks described?
- How many employees does Accenture have?
- What sustainability or ESG actions did Accenture take?

## ğŸ§ª Prompting Strategy

O sistema utiliza **Few-Shot Prompting** para guiar o LLM:
- Respostas concisas e factuais
- ExtraÃ§Ã£o de nÃºmeros quando disponÃ­veis
- Resposta "I don't know" quando a informaÃ§Ã£o nÃ£o estÃ¡ no contexto
- FormataÃ§Ã£o consistente de valores monetÃ¡rios

Implementado com `FewShotPromptTemplate` do LangChain, com exemplos especÃ­ficos para diferentes tipos de consultas.

## ğŸ“Œ Boas PrÃ¡ticas

- Consultas no mesmo idioma dos documentos (inglÃªs recomendado)
- Ajustar `k` (nÃºmero de chunks) conforme o tamanho do documento
- Usar MMR para reduzir redundÃ¢ncia nos trechos recuperados
- Validar respostas consultando as sources fornecidas

## âš ï¸ LimitaÃ§Ãµes Conhecidas

- Modelos de tamanho mÃ©dio (Flan-T5-base) podem perder detalhes finos em respostas muito complexas
- FAISS local Ã© adequado para projetos de pequena/mÃ©dia escala; para grande escala, considerar Qdrant, Weaviate ou PGVector
- Fontes sÃ£o exibidas de forma expandida no Streamlit para transparÃªncia total

## ğŸ“š Requisitos do Sistema

- Python 3.13+
- 4-8GB RAM recomendado (dependendo do modelo LLM escolhido)
- EspaÃ§o em disco: ~2GB para dependÃªncias e modelos

## ğŸ“¬ Sobre o Projeto

Projeto desenvolvido para portfÃ³lio com foco em aplicaÃ§Ãµes corporativas e anÃ¡lise de relatÃ³rios financeiros. Demonstra implementaÃ§Ã£o completa de um pipeline RAG do zero, incluindo ingestÃ£o, processamento, indexaÃ§Ã£o e geraÃ§Ã£o de respostas.
